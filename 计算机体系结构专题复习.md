---
title : 计算机体系结构专题复习
date : 2017年06月20日21:56:19
categories : review
tags : [计算机体系结构,复习]
---



# 计算机体系结构专题复习

made by © Isaac .Ty

## 第一章 计算机系统结构基础及并行性的开发

### 计算机系统的层次结构

- 机器：能存储和执行相应语言程序的算法和数据结构的**执行体**。
- 计算机语言：
  - 用以 述控制流程的、有一定规则的字符集合
    - 语言不是专属软件范畴，可以分属于计算机系统的各个层次，具有不同作用			
- 多层次结构：从使用语言的角度，一台由软、硬件组成的通用计算机系统可以被看成是按功能划分的多层机器组成的层次结构
- **多级层次结构**(机器---语言)

  - M5:应用语言机器--------应用语言
  - M4:高级语言机器--------高级语言
  - M3:汇编语言机器--------汇编语言
  - M2:操作系统机器-------作业控制语言
  - M1:传统机器-------------机器指令系统
  - M0:微程序机器----------微指令系统
- **编译**：用转换程序将高一级机器上的程序变换成低一级机器上的等效程序。
- **解释**：在低级机器上使用一串程序或指令来仿真高级机器上的一条语句或指令的功能。
- 模拟：在一种机器上实现另一种机器的指令系统
- 仿真：用微程序直接解释另一种机器指令系统的方法

### 计算机系统结构、计算机组成和计算机实现

- **系统结构**：计算机系统中各级界面的定义及其上下功能的分配
- **透明**：各个层级的程序员所看到的计算机属性不同，系统结构的研究内容之一就是要**确定属性**的透明性。
- 计算机组成：计算机系统结构的**逻辑实现**，包括机器级内部的**数据流和控制流**的组成以及逻辑设计等
- 透明性：客观存在的事物或属性从某个角度看不到。 在一个计算机系统中，低层机器的属性往往对高层程序员是透明的。计算机组成设计的内容，对传统机器程序员来讲一般是透明的

### 计算机系统的软、硬件取舍和性能评测及定量设计原理

#### 计算机性能评测

软件和硬件的逻辑等效性

- 硬件实现:速度快、成本高;灵活性差、占用内存少
- 软件实现:速度慢、复制费用低;灵活性好、占用内存多、易设计、可改性强、适应性强、设计周期短;

软件和硬件的分配

- 在满足应用的前提下，软硬件功能分配的比例主要看能否充分利用硬件、器件技术的进展，使系统具有高的性价比

软件和硬件的取舍原则

- 原则1：考虑现有硬件、器件条件下，系统要有**高的性价比**，主要从实现费用、速度和其他性能要求来综合考虑

  计算机系统产量比较大，增大硬件功能实现的比例才是合适的。	

- 原则2：考虑准备采用和可能采用的**组成技术**，使之尽可能不要过多或者不合理地限制各种组成、实现技术的采用

- 原则3：不能仅从**硬件**的角度考虑如何便于应用组成技术的成果和便于发挥器件技术的进程，还应从**软件**的角度把如何为编译和操作系统的实现以及如何为高级程序的设计提供更多、更好的硬件支持放在首位

- 结论：要缩短底**层系统结构**和**机器语言**与**上层高级语言、操作系统**和**程序设计环境之间**的语义差距，加强系统结构对软件设计的支持。

- CPU性能公式：

  - 程序执行的总指令条数$IC$

  - 平均每条指令的时钟周期数$CPI$

  - 时钟主频$f_c$

    $T_{CPU} =IC\times CPI \times \frac{1}{f_c}$

  - n种指令，每种指令的时钟周期数$CPI_i$，出现次数$I_i$

#### 定量设计原理

哈夫曼压缩原理

- 尽可能加速**高概率事件**远比加速处理**低概率事件**对性能提高要显著。

**Amdahl定律**

- 系统中某一部件由于采用某种更快的执行方式后整个系统性能的提高与这种**执行方式的执行频率**或**占总执行时间的比例**有关
- 对系统中的系能瓶颈部分采取措施提高后能得到系统性能改进的程度
- 系统加速比 $S_p=\frac{T_{old}}{T_{new}} = \frac {1}{(1-f_{new})+f_{new}/r_{new}}$ 
- 例1、例2、例3
- 改进效果好的高性能系统应是一个各部分性能均能平衡得得到提高的系统，不能只是其中某一个功能部件的性能得到提高

#### 程序访问的局部性规律

局部性分时间上的局部性和空间上的局部性

- 时间局部性：程序中近期被访问的信息项很可能马上将被再次访问。
- 空间局部性：指那些在访问地址上相邻近的信息项很可能会被一起访问。

存储器体系的构成就是以访问局部性原理为基础的


​	

## 第二章 数据表示、寻址方式与指令系统

### 数据表示

#### 数据表示和数据结构

**数据表示**：能由机器**硬件识别**和**引用**的数据类型，即它有对这种类型的数据进行操作的指令和运算部件。

**数据结构**：通过软件映像，变换成机器中所具有的数据来表示实现。

不同的**数据表示**可为数据结构的实现提供不同的支持，表现为实现效率和方便性的不同。数据结构和数据表示是**软件和硬件的交界面**。

**数据表示的确定实质上是软、硬件的取舍问题**

#### 高级数据结构

1. 自定义数据表示

   标志符和数据描述符

   - ***标志符***

     让每个数据带上**类型标志位**以说明数据值究竟是二进制整数、十进制整数……将数据类型与数据本身连在一起

     优点（6条）：简化指令系统和程序设计、简化编译程序、便于通过硬件实现一致性校验、硬件自动变换类型、数据库系统实现和数据类型无关的要求使程序不用修改即可处理多种不同类型的数据、支持软件调试和应用软件开发

     缺点（2条）：每个数据字增设标志符增加程序所占主存空间，但是缩短了操作码位数；采用标志符降低指令执行速度。

   - ***数据描述符***

     描述符与数据分开存放，描述所要访问的数据是整块的还是单个的，访问该数据块或数据元素所要的地址及其它信息

     优点：(1)**描述符**实现阵列数据的索引要比用**变址方法**实现更方便，且便于检查程序中的阵列越界错误；(2)为向量、数组数据结构的实现提供了一定的支持。

2. ***向量、数组数据表示***

   增设向量、数组数据表示提供对向量、数组数据结构提供支持

   优点：加快形成元素地址；用一条向量、数组指令流水可同时对整个向量、数组进行高速处理；硬件判断下标是否越界，并让越界判断和元素运算并行；节省存储空间和处理时间；简化编译程序

   向量处理机：具有向量表示和相应的向量运算指令的计算机

   标量处理机：不具有向量表示和相应的向量运算指令的计算机

3. ***<u>浮点数表示方式的核心</u>***：数据字长与这种数据表示方式的**表数范围**、**表示精度**和**表数效率**之间的关系

### 寻址方式（重点）

指令按什么方式寻找到所需的操作数或信息

#### 寻址方式的三个面向

**面向主存**：主要访问主存，少量访问寄存器

**面向寄存器**：主要访问寄存器，少量访问主存和堆栈

**面向堆栈**：主要访问堆栈，少量访问主存和寄存器

#### 寻址方式在指令中的指明

- 占用**操作码的某些位**来指明
- 在**地址码部分**专门设置寻址方式位字段指明

#### 寻址方式的种类

- 寄存器寻址：指令中的地址码是寄存器的编号，而不是操作数地址或本身
  - 寄存器直接寻址：寄存器内容即操作数
  - 寄存器简介寻址：寄存器内容是操作数的地址
- 立即寻址：指令的地址码字段直接是操作数
- 直接寻址：指令的地址码字段直接指出操作数在主存中的地址
- 间接寻址：指令的地址码字段指向的存储单元存储的不是操作数，而是操作数的地址
- 相对寻址：把程序计数器PC的内容加上指令中的形式地址而形式操作数的有效地址
- 变址寻址：将变址寄存器的内容加上指令中的形式地址而形成操作数有效地址，实现程序块的规律性变化
- 基址寻址：将基址寄存器的内容加上指令中的形式地址而形成操作数有效地址，优点是可以扩大寻址能力

#### 程序在主存中的定位技术

**逻辑地址**：程序员编写程序时使用的地址

**物理地址**：程序在主存中的实际地址

- 静态再定位：在目的程序装入主存的时候，由装入程序用**软件方法**把目的程序的**逻辑地址变换为物理地址**，程序执行时，**物理地址不再改变**。 不利于多道程序执行
- 动态再定位：基址寻址。
  - 增加相应的基址寄存器和地址加法器硬件，程序不做变换直接装入主存的同时，将装入主存的起始地址装入对应该道程序使用的基址寄存器中。
  - 程序执行时，只要通过**地址加法器**将**逻辑地址**加上**基址寄存器的程序基址**形成有效地址后进行访存操作即可。
  - 需要通过上、下界寄存器进行判断
- 虚实地址映像表
  - 采用虚拟存储器，增加映像表硬件，使得程序空间可以超过主存空间
  - 基址寻址。B为基址寄存器号，存放24位的基地址。(B)~(8-13)~+D形成24位宽的访存物理地址
- 物理主存中的信息分布
  - IBM370
  - 任意存储
  - 整数倍存储


### 指令系统的设计和优化

#### 指令系统设计基本原则

**指令系统**是程序设计者看到的机器的主要属性，是软、硬件的主要界面，在很大程度上决定了计算机具有的基本功能

指令系统的设计主要包括**指令的功能**（操作类型、寻址方式和具体内容）和**指令格式**的设计

#### 指令设计的步骤

- 根据应用，初拟指令的分类和具体指令
- 试编出用该指令系统设计的各种高级语言的编译程序
- 用大量测试程序进行模拟测试，看指令系统的操作码和寻址方式效能是否都比较高
- 将程序中高频出现的指令串复合改成一条强功能新指令，即改用硬件方式实现；而将频度很低的指令操作改成基本的指令组成的指令串来实现，即用软件的方式实现

##### 指令类型

- 非特权型：主要供应用程序员使用，也可供系统程序员使用，包括算术逻辑运算、数据传送、浮点运算、字符串、十进制运算、控制转移及系统控制
- 特权型：系统程序员使用，用户无权使用，包括启动I/O、停机等待、存储管理保护、控制系统状态、诊断等；

##### 编译程序设计

- 设计原则：如何支持编译系统能高效、简易地将源程序翻译成目标代码
  - 规整性、对称性、独立性和全能性、正交性、可组合性、可扩充性

##### 系统设计

- 指令码密度适中、兼容性、适应性

#### 指令格式的优化

指令由**操作码**和**地址码**两部分组成。

**指令格式的优化**：用最短的位数来表示指令的操作信息和地址信息，使程序中指令的平均字长最短。（哈弗曼压缩）

操作码的优化：缩短指令字长，减少程序总位数及增加指令字能表示的操作信息和地址信息。

##### 操作码优化

操作码$I_i$的使用频度$p_i$

操作码的**信息源熵**  (信息源所含的平均信息量)   $H=- \sum _i p_i \log p_i$

信息冗余度    $\frac {实际平均码长-H}{实际平均码长}$  

##### 哈夫曼压缩（计算：哈夫曼树构成）

当各种事件发生概率不均等时，采用优化技术，对发生概率高的事件用短的位数来表示，而对出现概率较低的事件允许使用较长的位数来表示，以缩短表示的平均位数。

用于代码压缩、程序压缩、空间压缩和时间压缩

编码长度不唯一，但是平均码长唯一

步骤：

- 将所有指令的使用频度由小到大排序，每次选择其中最小的两个频度合并成一个频度，使它们二者之和称为一个新结点。再按该频度大小插入到余下未参与结合的频度中。直到全部形成根结点为止。
- 对每一个结点向下延伸，分出两个分支，分别用一位代码的”0“或”1“表示。

由于短码不可能是长码的前缀，从而保证了解码的唯一性和事实性

##### 基于哈夫曼编码的扩展操作码（计算：指令设计）

- 完全哈夫曼编码码长种类太多，不利于译码和实现

- 界定于定长二进制编码和完全哈夫曼编码之间的一种编码方式

- 操作码长度不固定，但只有有限种选择

- **高概率使用短码，低概率使用长码**；短码不能是长码的前缀（11为扩展码）

- 缩短操作码的平均长度，以减低信息冗余度

  等长15/15/15...  扩展法    等长 8/64/523扩展法

- 指令设计：基于编码给机器操作码编码


##### 指令字格式的优化

- 主存按位编址，指令字不按整数边界存储，而是逐条紧挨存储。会直接带来程序的总位数减少，然而访存指令速度下降。
- 指令字按整数边界存储
- 此处有图
- 扩大操作数地址的寻址范围
  - 采用基址寄存器寻址、相对寻址或寄存器寻址
  - 基于分段的编址（段号+段内地址）
- 操作数的地址码长度可以有**很宽的变化范围**，可以与可变长操作码配合，可以显著减少存储空间的浪费。
- 多种地址制，同一种地址制还可以采用多种地址形式和长度，也可以直接用空白来存放直接操作数或常数。
  - 多种地址制图
  - 同种地址制下的多种地址形式和长度
- 优化措施
  - 采用**扩展操作码**，根据指令的**频度**的分布选择合适的编码方式，以缩短操作码平均码长。
  - 采用**多种寻址方式**，以缩短地址码长，并在有限地址长度内提供更多信息
  - 采用**多种地址制**，增强指令功能，从宏观上缩短程序长度，加快程序执行速度
  - 在**同种地址制内再采用多种地址形式**，让每种地址字段可以有多种长度，且让长操作码与短操作码进行组配
  - 在维持指令字的存储器中按整数边界存储的前提下，使用多种不同的指令字长计算


##### 指令编排（P63)

### 指令系统的发展和改进

## 第三章 存储、中断、总线与输入/输出系统

### 存储系统的基本要求和并行主存系统

#### 存储系统的基本要求

- 大容量、高速度、低价格

- 存储器**容量** $S_M=W \times l \times m$ 

  $W $为存储器字长，$l$为存储器字数，$m$为并行存储器体数

- 存储器速度

  - 访问时间$T_A$：存储器从接收访存读申请至信息被读到数据总线上的时间
  - 存储周期$T_M$：连续启动一个存储器所需要的间隔时间（$T_M>T_A$)
  - 频宽（带宽）$B_M$：存储器可提供的数据传送速率
    - 最大频宽：单体$B_M = W /T_M $，m个存储体并行的最大频宽 $B_M = W\times m/T_M$
    - 实际频宽

#### 并行主存系统

##### 单体单字存储器

当并行的存储器公用一套地址寄存器和地址译码电路时称为单体方式

每次访问一个存储器的一个字

最大的频宽$B_M = W /T_M$ 

##### 单体多字存储器

把**存储器字长**增加n倍，为保持总容量不变，把存储器字数（地址数）相应减少n倍

在一个周期内访问n个数据

最大频宽 $B_M = W \times n / T_M$ 

**取指令冲突**：在遇到程序转移而且转移成功时，一个存储周期读出的n条指令中，后面的指令将无用

**读操作数冲突**：一次同时读出的n个操作数，不一定都有用

**写数据冲突**：必须凑齐n个数之后才能一起写入存储器

**读写冲突**：当要读出的一个字和要写入存储器的字处在同一个存储字内时，无法在一个存储周期内完成

##### 多体单字

由多组容量小、字长短的存储器片子组成，每个存储片子都有自己的地址译码、读/写驱动等外围电路

每个存储片子都有独立的地址译码、读/写驱动等外围电路

##### 模m低位交叉编址

- CPU字在主存中按模m低位交叉编址
  - 单体容量为l的m各分体，其$M_j$体的编址模式为$m\times i +j $，其中$ i = 0,1,2,..,l-1$ , $j=0,1,2,…,m-1$
- 寻址规则
  - 体地址 $j = A \mod m$ 
  - 体内地址 $i = A / m$ 
    - $M_0 : 0,m,2m,…,m(l-1)+0$ 
    - $M_i:i,m+i,2m+i,…,m(l-1)+i$ 
- 适合于单处理机内 数据存储和带Cache主存

##### 模m高位交叉编址

##### 定量分析(P85)

转移概率$\lambda$，每个周期能访问的平均字数 $B = \frac {1-(1-\lambda)^m}{\lambda}$

##### 结论

* 从最坏情况考虑，设所有申请(包括指令和数据)都是全随机的，用单来单服务、先来先服务的排队论模型进行模拟，可得出随 $m$ 的提高，主存频宽只是以近似$\sqrt m$的关系改善
* 当然，指令流和数据流也不会是全随机的，因此，𝐵的值总是会比$\sqrt m$的值要大
* 正是因为程序的转移概率不会很低，数据分布的离散性较大，所以单靠增大𝑚来 高并行主存系统的频宽是有限的，而且性能价格比还会随𝑚的增大而下降，就必须从系统结构上进行改进，采用存储体系

### 中断系统

CPU终止正在执行的程序，转去处理随机提出的请求，待处理完毕后，再回到原先被中断的程序继续恢复执行的过程称为“中断”

相应和处理各种中断的软硬件系统总称为**中断系统**

- 内部中断：由CPU异常引起
- 外部中断：由中断信号引起
  - 可屏蔽中断
  - 不可屏蔽中断
- 软件中断：由自陷指令引起，用于操作系统服务

#### 中断的分类和分级

中断源：引起中断的各种事件

**中断请求**：中断源向中断系统发出中断的申请

**中断响应**：允许其中断CPU现行程序的运行，转去对该请求进行预处理，包括保存好端点现场，调出有关该中断的中断服务程序

##### 中断的分类

对中断进行分类，对每一类中断给定一个硬件的中断服务入口，再由软件分支转入相应的中断处理程序

##### 中断和异常

异常：由执行**现行指令**引起的临时停止事件，如运算结果溢出、页面失效等，一般不能屏蔽，应予立即相应和处理

中断：指那些**与当前进程运行无关**的请求临时停止的事件，如机器故障中断请求、外设中断请求、定时中断请求等，可以屏蔽、未被响应的中断源保留在中断字寄存器中，直至屏蔽解除后得到响应和处理

##### 中断的分级

同一类中各个中断请求的响应和处理的优先次序，一般由软件或通道来管理；而不同类的中断要根据其性质、紧迫性、重要性以及软件处理的方便性分成不同级别

#### 中断的响应和处理次序(P89)

中断响应次序（处理中断流程）

- 同时发生多个不同中断类的中断请求时，中断响应硬件中的**排队器所决定的响应次序**
- 一般在处理某级中某个中断请求时，是不能被与它同级的或比它低一级的中断请求所中断，只有比它高一级的中断请求才能中断其处理，等响应和处理完毕后再继续处理原先那个中断请求

中断处理次序

- 中断处理完的次序
- 由于中断处理程序也可能被中断，中断处理次序可能不同于中断响应次序

##### 结论

* 只要操作系统根据需要软的方法，改变各级中断处理程序的中断级屏蔽位状态，就可以改变实际的中断处理。这就是中断系统采用软、硬件结合的好处
* **中断响应用排队器**硬件实现可以加快响应和断点现场保护，中断处理采用软的技术可以 供很大的灵活性，因此，中断系统的软、硬件功能的实质是中断处理程序软件和中断响应硬件的功能分配
* 为了改善性能，用软件实现的功能，可以部分改用硬件来实现

#### 中断系统的软、硬件分配

### 总线系统

**总线**：用于互连计算机、CPU、存储器、I/O端口及外部设备、远程通信设备间**信息传送通路的集合**

总线系统：总线与其相配合的**附属控制电路**

按照信息传送功能、性能的不同，总线系统包括**数据线**、**地址线**、**时序**和**中断信号**等控制/状态线、**电源线**、地线以及**备用线**等

- 数据线的根数决定同时传送的**数据位数**，即数据通路宽度
- 地址线的根数决定**直接寻址的范围**
- 控制/状态线决定总线的**功能和使用能力**
- 备用线用于**系统功能的扩充**

#### 总线的分类

##### 按系统中的位置

- 芯片级：CPU芯片内的总线;
- 板级：连接插件版内的各组件，局部总线、内部总线;
- 系统级：系统间或主机与I/O接口或设备之间的总线

##### 按信息传送方向

- 单向传输
- 双向传输
  - 半双向：可沿相反方向传送，但同时只能向一个方向传送
  - 全双向：可以同时向两个方向传送，速度快、造价高、结构复杂

##### 按使用方法

* 专用总线：只连接**一对物理部件**的总线
  * 优点：
    * 多个部件可以同时收发信息，不争用总线，系统流量高
    * 通信时不用指明源和目的，控制简单;
    * 任何总线的失效只会使连接该总线的两个部件不能直接通信，但它们仍可以通过其他部件间接通信，因而系统可靠
  * 缺点：
    * 总线数多，总线数与部件数成平方倍关系增加
    * 难以小型化、集成电路化
    * 总线较长时，成本相当高
    * 利用率低
    * 不利于系统模块化

* 非专用总线：可以被多种功能或多个部件分时共享，同一时间只有一对部件可使用总线进行通信

  * 优点：

    * 总线数少、造价低
    * 总线接口标准化，模块性强
    * 可扩充能力强
    * 部件的增加不会使电缆、接口和驱动电路激增
    * 易用多重总线提高总线的带宽和可靠性，使故障弱化
  * 缺点：
    * 系统流量小，经常会出现争用总线的情况，降低效率，共享总线失效会导致系统瘫痪


#### 总线的控制方式

非专用总线上的多个设备或者部件同时请求使用总线，使得由**总线控制机构**按某种优先次序裁决，保证只有一个高优先级的申请者首先取得对总线的使用权

集中式控制：总线控制机构基本集中在一起，不论是在连接到总线的一个部件中，还是在单独的硬件中

分布式控制：总线控制逻辑分散在连到总线的各个部件间

##### 集中式控制

优先次序的确定可以有**串行连接**、**定时查询**和**独立请求**三种不同的方式，也可以是它们的结合。采用何种方式取决于控制线数目、总线分配速度、灵活性、可靠性等因素的综合考虑

1. **集中式的串行连接**

   - 所有部件都经公共的“总线请求”线向总线控制器发出请求，
   - 当“总线忙”信号未建立，总线空闲，请求响应，送出“总线可用”信号，串行通过每个部件。
   - 如某个部件接收到“总线可用”信号但未发送请求，则送往下一个部件，如该部件发出过请求，则停止信号
   - 建立“总线忙”，清除请求信号，准备数据传送
   - 数据传送期间，“总线忙”维持“总线可用”的建立
   - 传送完，去除“总线忙”和“总线可用”信号

   优先次序是由“总线可用”线所接部件的物理位置决定的

   优点：

   - 选择算法简单，控制总线少(3根)
   - 部件增减容易，可扩充性好
   - 逻辑简单，容易通过重复设置提高可靠性

   缺点：

   - 对“总线可用”线及其有关电路的失效很敏感
   - 优先级是线连固定，不能由程序改变，灵活性差增加
   - “总线可用”信号顺序脉动地通过各个部件，限制总线的分配速度
   - 受总线长度的限制，增减或移动设备受到限制

2. **集中式定时查询**

   - 总线上的每个部件通过“总线请求”线发出请求
   - 若总线处于空闲，“总线忙”未建立，总线控制器收到请求后，让计数器开始计数，定时查询各部件以确定是哪个部件发出请求
   - 查询到请求发出部件，该部件建立“总线忙”，计数器停止计数，控制器停止查询
   - 去除该部件的“总线请求”，让该部件获得总线使用权，传送完成后去除“总线忙”
   - 如果总线分配前计数器清0，同串行链接；如果总线分配前不清0，则是循环优先级；如果总线分配前计数器设置某个初值，则指定这个部件为最高优先级;如果总线分配前将部件号重新设置一下，则可以指定各部件为任意所希望的优先级

   优点：

   - 因计数器初值，部件号均可由程序设定，优先次序可由程序控制，灵活性强
   - 可靠性高

   缺点：

   - 控制线数较多，需2+log2N,扩展性稍差
   - 控制较为复杂
   - 速度取决与计数信号的频率和部件数，不能很高

3. **集中式独立请求**

   - 共享总线的每个部件各自都有一对“总线请求”和“总线准许”线
   - 总线控制器根据某种算法对同时送来的多个请求进行仲裁

   优点：

   - 总线分配速度快，不用查询
   - 可以使用程序可控的预订方式、自适应方式、循环方式或它们的混和方式灵活确定下一个使用总线的部件
   - 能方便地隔离失效部件的请求

   缺点：

   - 控制线数量多，N个设备必须有2N+1根控制线
   - 总线控制器复杂

#### 总线的通讯方式

##### 同步通讯

两个部件的信息是通过**定宽**、**定距**的**系统时标**进行同步的

* 传送率高，受总线长度影响小
* 时钟在总线上的时滞可能会造成同步误差，时钟线上的干扰信号容易引起误同步
* 为提高可靠性，目的部件需要对数据是否正确接受予以回答：正常时不回答，出错时在同步时间片过去后向源部件发送出错信号，使之重发数据

##### 异步通讯（图什么意思）

- 单向源(目)控制：通讯过程只由目的或源部件中的一个控制。
  - 优点：简单、高速
  - 缺点：没有来自目的部件的信息指明数据传送是否有效;不同速度之间的部件之间通信比较复杂;部件内需设置缓冲器以缓冲来不及处理的数据;效率低，高速部件难以发挥效能;要求“数据准备”信号干扰要小，否则易误认成有效信号
- 双向控制：由源和目的双方控制
  - 单向控制的缺点是不能保证下一数据传送之前让所有数据线和控制线的电平信号恢复成初始状态，从而可能造成错误状态
  - 异步双向互锁方式虽然增加了信号沿总线来回传送的次数，使控制硬件变得更加复杂
    - 异步互锁可以解决在下一个“数据准备”到达目的端时，上一个“数据接受”仍处于高电平
      - 适应各种不同速度的I/O设备，保证数据传送的正确性，且有较高的数据传送速率(其速率为源部件和目的部件中相对较低的速率来通信，比同步方式总是以所有部件中最低的速率来通信的效率要高)		

#### 数据宽度与总线线数

##### 数据宽度

数据宽度：I/O设备取得I/O总线后所**传送数据的总量**，

数据通路宽度：数据**总线的物理宽度**(即一个时钟周期所传送的数据量)

**一个数据宽度可能需要多个数据周期才能完成**

数据宽度类型

- **单字(单字节)宽度**适合输入机、打印机等低速设备
- **定长块宽度**适合于磁盘等高速设备
- **可变长块宽度**适合于高优先级的中高速磁带、磁盘等设备

##### 总线的线数

* 总线线数越多，成本越高，干扰越大，可靠性越低，占用空间也越大，当然，传送速度和流量也越高
* 总线长度越长，成本越高，干扰越大，波形畸变越严重，可靠性越低
* 因此，总线增长，线数就应该越少
* 总线线数可以通过用线的组合、编码，以及并/串—串/并转换来实现，但一般会降低总线的流量

### 输入/输出系统

#### 输入输出系统概述

输入输出系统：包括**输入输出设备**、**设备控制器**及与**输入输出操作有关的硬件**

输入输出系统：计算机系统中处理机与主存储器之外的部分

**输入输出系统**是处理机与外界进行数据交换的通道。

输入输出设备：与处理机有关的、除人以外的各种设备

##### 输入输出系统的特点

- 异步性：
  - 输入输出设备通常不使用统一的中央时钟，各个**设备按照自己的时钟工作**，但又要在某些时刻接受处理机的控制
  - 处理机与外围设备之间，外围设备与外围设备之间能够**并行工作**
- 实时性：
  - 对于一般外部设备：可能丢失数据，或造成外围设备工作的错误
  - 对于实时控制计算机系统，如果处理机提供的服务不及时，可能造成巨大的损失
  - 对于处理机本身的硬件或软件错误：如电源故障、数据校验错、页面失效、非法指令、地址越界等，处理机须及时处理
  - 对不同类型的设备，必须具有与设备相配合的多种工作方式
- 与设备无关性：
  - 独立于具体设备的标准接口。例如，串行接口、并行接口、SCSI(SmallComputer System Interface)接口等
  - 计算机系统的使用者，在需要更换外围设备时，各种不同型号，不同生产厂家的设备都可以直接通过标准接口与计算机系统连接
  - 处理机采用统一的硬件和软件对品种繁多的设备进行管理
  - 某些计算机系统已经实现了即插即用技术


#### 通道处理机的工作原理和流量设计

##### 通道处理机工作原理

* 用户一般不能直接安排输入/输出操作，而通过程序状态的切换来实现输入输出，以保证系统的可靠性
* 中央处理机用来控制外部设备操作用的输入/输出指令称为**管态指令**
* 用户在**目态程序**中不能直接使用**管态指令**，只能使用要求输入/输出的广义指令，然后进入相应的管理程序执行输入/输出的管态指令。

##### 启动I/O指令

选择通道；选择子通道；选取通道指令；选取控制器、设备；向设备发送启动命令；启动成功，则结束通道开始选择设备期，进入通道程序，并退出管态程序，返回目态程序

##### 通道数据传送方式

- **字节多路**：适合于连接像光电机的字符类低速设备

  - 送**一个字符**(字节)的时间很短，但字符(字节)间的等待时间很长
  - 以字节交叉方式轮流为多台低速设备服务
  - 可有多个子通道，独立执行通道命令，并行操作

- **数组多路**：适合于连接多台像磁盘的高速设备

  - 传送速率很高，但传送开始前的**寻址辅助操作时间很长**
  - 成组交叉方式，传送完K个字节数据后重新选择下一个设备

- **选择通道**：适合于连接优先级高的磁盘等高速设备

  - 独占通道

  - 在数据传送期内只选择一次设备

    ​	

##### 通道流量的设计

通道流量是通道在数据传送期间内，单位时间传送的字节数。它能达到的最大流量称为通道极限流量

通道的极限流量与其工作方式、数据传送期内**选择一次设备的时间** $T_S$ 和**传送一个字节的时间** $T_D$长短相关

1. 字节多路的通道极限流量

   每选择一台设备只传送一个字节   

    $f_{max \cdot byte} = \frac {1}{T_S+T_D}$ 

2. 数组多路的通道极限流量

   每选择一台设备就能传送完K个字节，如果要传N个字节，就要分N/K次传送，每次传送选择一次设备

   $f_{max\cdot block} = \frac {K}{T_S+KT_D} = \frac{1}{\frac {T_S}{K} + T_D}$ 

3. 选择通道的通道极限流量

   每选择一台设备就把N个字节全部传送完

   $f_{max \cdot select} = \frac {N}{T_S+NT_D} = \frac{1}{\frac{T_S}{N}+T_D}$ 

如果通道的$T_S$ 、$T_D $确定时，且N>K时，有 

$f_{max\cdot select} \ge f_{max\cdot block} \ge f_{max\cdot byte}$

设备要求通道的实际最大流量与三种通道的工作方式有关

- 字节多路是该通道连接各设备的字节传送速率之和

  - $f_{byte\cdot j} = \sum ^{p_j}_{i=1} f_{i\cdot j}$

- 数组多路和选择通道是所连接各设备的字节传送速率中之最大者

  - $f_{block\cdot j} = max f_{i\cdot j} , f_{select\cdot j} = max f_{i\cdot j}   i = 1,…,p_j$ 

  $j$：通道编号  $f_{i,j}$ ：为第$j$号通道上所挂的第$i$台设备的字节传送速率

  $p_j$：为第$j$号通道上所连接的设备的台数

- 为了保证第j号通道上所挂设备在满负荷的最坏情况下都不丢失信息，必须使设备要求通道的实际最大流量不超过通道的极限流量

  $f_{byte\cdot j}\le f_{max\cdot byte\cdot j}$

  ...

- 上述流量设计的基本条件只保证了宏观上设备不丢失数据，并不能保证每一个局部时刻都不丢失信息

- 通常高速设备请求的响应优先级比较高，高速设备频繁发出请求并总是优先得到响应和处理，使得速率较低的设备长期得不到通道而丢失信息。

- 在设备或设备控制器中设置一定容量的缓冲器来缓冲得不到及时处理的数据，或是通过动态 高低速设备的响应优先级

## 第四章 存储体系

### 基本概念

#### 存储体系及其分支

**存储体系**：在构成存储系统的几种不同的存储器（M~1~-M~n~）之间，配上辅助软件或硬件，使之从应用程序员的角度看，在逻辑上是一个整体（对应用程序员透明）

等效访问速度接近$M_1$，容量接近于$M_n$，每位价格接近于$M_n$。

##### 主存—辅存存储层次（容量）

虚拟存储器：由于主存容量无法满足需求，因此在主存和辅存之间，增设辅助的软、硬件设备，使它们形成统一整体

##### Cache—主存存储层次（速度）

由于主存速度满足不了要求，因而在CPU和主存之间增设高速、小容量、每位价格较高的Cache，用辅助硬件将其和主存构成整体，称为“Cache-主存存储层次”

##### 多级存储层次

从CPU角度看，整个存储体系是一个整体，其速度接近于$M_1$，容量接近于$M_n$，每位价格接近于$M_n$

#### 存储体系构成依据

当CPU需要某个地址的内容的时候，总是希望该内容在速度最快的$M_1$当中

未来被访问信息的可预知性：

- 时间局部性：在最近的未来所要用到的信息很可能是现在正在使用的信息
- 空间局部性：在最近的未来所要用到的信息很可能是何现在正在使用的信息在程序空间上是邻近的

不必将整个程序整体存入$M_1$，只需要将近期访问过的块（或页）调入$M_1$

预知的准确性是存储层次设计好坏的主要标志，很大程度取决于所用的算法和地址映像变换方式

#### 存储体系的性能参数（老师PDF中无）

#### 存储器层次结构设计的问题

- **映像方式**：低层存储器的块**按什么规则**装入高层存储器
- **映像机构**：映像方式的实现，如何识别和查找高层存储器的信息块
- **替换策略**：访问失效后，如何淘汰信息块，而换新块
- **写策略**：写操作发生时采用何种策略以**保持相邻两级存储器中数据的一致性**，发生写操作失效时是否将背写的块从低层存储器取入高层存储器

### 虚拟存储器

#### 虚拟存储器的管理方式

虚拟存储器通过**地址映像表**机构来实现在主存中的定位。将程序分割成**段**或者**页**，用相应的映像表指明该程序某个段或页是否已装入主存；

- 若已装入，指明在主存中的**起始地址**
- 若未装入，去辅存中调入段或者页，装入主存后再在映像表中建立号程序空间与实存空间的地址映像关系

程序执行时先**查映像表**，将程序**虚地址**变成**实地址**后再访问主存

根据存储映像算法的不同，有多种不同的存储管理方式的虚拟存储器，其中主要由段式、页式、段页式

##### 段式管理

**段**是程序逻辑独立的模块，每个段从0开始编址。当某个段调入主存时，只要系统赋予该段一个基址，就可以由该**基址**和单元的**段内地址**形成主存内的**实际地址**。将主存按段分配的存储管理方式称为段式管理

优点：

- 使大程序分模块编址，使得多个程序员并行编程，缩短编程时间，在执行或者编译过程中对不断变化的变长短也便于处理
- 便于多道程序共用已在主存内的程序和数据
- 由于各段是按其逻辑特点组合的，因而容易以段为单位实现存储保护

缺点：

- 段长度完全取决于自身，主存中起点随意，给调入段分配主存带来了困难
- 需要构造复杂的段映像表，还需要为主存系统建立一个实主存管理表，包括占用区域表和可用区域表

##### 页式管理

页式虚拟存储器把**虚拟空间**机械地划分成一个个**固定大小的块**，每块称为一页，把**主存储器的地址**空间也按虚拟地址空间**同样的大小**划分为页。页是一种**逻辑上的划分**，可以由系统任意指定。

**虚拟地址空间**中的也称为**虚页**，主存地址空间中的页称为**实页**

每个用户使用**基址寄存器**（CPU内），通过用户号U可以直接找到与该用户程序相对应的基址寄存器，从这个基址寄存器中读出**页表起始地址**。访问这个页表地址，把得到的主存页号P与虚地址中的业内偏移直接拼接起来得到主存实地址。

- 页表项简单，查找速度快；
- 页面大小固定不利于系统的效率；
- 页式管理在存储空间较大时，由于页表过大，效率降低；
- 存储空间的保护困难

优点：

- 主存储器的利用率比较高
- 页表相对比较简单
- 地址变换的速度比较快
- 对磁盘的管理比较容易

缺点：

- 程序的模块化性能不好
- 页表很长，需要占用很大的存储空间

##### 段页式管理

- 页式：对应用程序员完全透明，由系统划分。

  - 硬件较少，地址变换速度快，
  - 调入操作简单，静态连接程序;

- 段式：段独立，有利于程序员灵活实现段的连接、段的扩大/缩小和修改，而不影响其他段，易于针对其特定类型实现保护，把共享的程序或数据单独构成一个段，从而易于实现多个用户、进程对共用段的管理，动态连接程序;

- 段页式：把**实存**机械地等分成固定大小的**页**，**程序**按模块**分段**，每个段又分成与主存页面大小相同的页。

#### 页式虚拟存储器的构成

##### 地址映像和变换

- **地址映像**：将每个**虚拟存储单元**按某种规则装入实存，即建立多用户虚地址$N_s$与实存地址$n_p$之间的对应关系。
- **地址变换**：程序按照这种映像关系装入实存后，在执行时，多用户虚拟地址$N_s$如何变换成对应的实地址$n_p$
- **页面冲突**：发生两个以上的虚页想要进入主存同一个页面位置而产生页面争用现象。

##### 地址变化规则

减少实页冲突概率，硬件少、成本低，实现方便、变化速度快

由于虚拟空间远远大于实存空间，因此页式虚拟存储器常采用全相联映像

**全相联映像**（页表法）：任何虚页可以映像装入到任何实页位置。**冲突概率最低**

**相联目录表法**：把页表压缩成只存放已装入主存的那些**虚页号**与**实页位置$n_v$**的对应关系

比较的表格

##### 页面替换算法(P125)

- 页面替换发生时间：

  当发生页面失效时，要从磁盘中调入一页到主存。如果主存所有页面都已经被占用，必须从主存储器中淘汰一个不常使用的页面，以便腾出主存空间来存放新调入的页面

- 替换算法的确定：

  - 主存命中率
  - 是否便于实现，软、硬件成本

- 页面替换算法使用的场合

  - 虚拟存储器中，主存页面的替换，一般用软件实现
  - Cache块替换一般用硬件实现
  - 虚拟存储器的快慢表中，块表存储字的替换用硬件实现
  - 虚拟存储器中，用户基地址寄存器的替换用硬件实现

- 随机算法（Random，RAND）：用软的或硬的随机数产生器来形成主存中被替换的页号

  - 简单，易于实现
  - 没有利用历史信息
  - 命中率低，很少使用

- 先进先出算法（First-In-First-Out，FIFO）：选择最早装入主存的页作为被替换的页

  - 操作系统为主存页面表中给每个实页配置一个计算器字段，每当一页装入时，让该页的计数器清零，其他已装入页的计数器都加“1”
  - 需要替换时，计数器值最大的页号即最先进入主存而且现在准备被替换掉的页号
  - 虽然使用历史信息，但是不一定反映程序的局部性

- 近期最少使用算法（Least Recently Used，LRU）：选择近期最少访问的页被作为替换的页

  - 配备计数器
  - 比较正确反映程序的局部性

- 优化替换算法（Optimal Replacement Algorithm，OPT）：在时刻t找出主存中每个页**将要用到时刻$t_i$**，然后选择其中$t_i-t$最大页作为替换页。

  - 理想的算法


### 高速缓冲存储器

#### 工作原理和基本结构

用以弥补主存速度的不足，在处理机和主存之间设置一个高速、小容量的Cache，构成Cache—主存存储层次。CPU来看，速度接近于Cache，容量却是主存的

##### 工作原理

图

##### 基本结构

- 把**主存**和**Cache**机械等分成相同大小的块（行），块比页小得多
- 除Cache到处理机的通路外，还设有主存到处理机的通路
- 处理机到Cache是字传送，主存到Cache是块传送

##### Cache设计要素

- **Cache**和**CPU**是同类型的半导体器件
- 访问**Cache**时间是访问**主存**时间的1/4到1/10；
- Cache在物理位置上**靠近CPU**，不在主存，减少传输延迟
- **Cache-主存**间的地址映像和变换，以及替换、调用算法用硬件实现

#### 地址映像与变换

##### 地址映像

将每个主存块按某种规则装入Cache，并建立主存地址与Cache地址之间的对应关系

##### 地址变换

主存块按照映像关系转入Cache后，每次访问Cache如何将主存地址变换成Cache地址

##### 选取地址映像方法考虑的主要因素

- 地址变换的硬件容易实现
- 地址变换的速度要快
- 主存空间利用率要高
- 发生块冲突的概率要小

##### 全相联映像与变换

主存中的任意一块都可以映像到Cache中任意一块。

目录表硬件方式实现

**相联目录表法**（主存地址到Cache地址映射）

特点：冲突概率低、空间利用率高、地址变换快

缺点：目录表代价大；查表速度难提高

##### 直接映像与变换

- 映像规则

  主存中一块只能映像到Cache的一个特定的块中

  主存第i块只能映像到  $i\mod 2^{n_{cb}}$块位置上

  **<u>*整个Cache地址与主存地址地位部分完全相同*</u>**

- 区号存储器

  存放Cache中每一块位置目前被主存中的哪个区的块所占用的区号

- 优点

  硬件实现简单，不需要相联访问存储器

  访问速度较快，实际上不做地址变换

- 缺点

  块的冲突率较高

  出现大量空闲块

- 很少使用


##### 组相联映像与变换

映像规则：**各组之间直接映像，组内各块全相联映像**

将**Cache空间**和**主存空间**都分成组，每组S块（$S = 2^s$）；将Cache分成Q组（$Q=2^q$），整个Cache作为一个区。主存分成和Cache同样大小的$2^{n_d}$个区，每个区包含Q组

变换 ： 图

优点：

- 块冲突概率低
- 块的利用率大幅度提高
- 块失效率明显降低

缺点：实现难度和造价要比直接映像方式高

地址变换过程：用主存地址的组号G按地址访问块表存储器。把读出来的一组**区号**与**主存地址中区号和块号**进行相联比较，如果有相等的，表示Cache命中；如果没有相等的，表示Cache没有命中

##### 段相联映像

映像规则：组间全相联，组内直接映像

#### Cache存储器的LRU替换算法的硬件实现（不在老师PDF）

#### Cache存储器的透明性及性能分析

##### Cache存储器的透明性分析及其解决方法

由于Cache存储器的**地址变换**和**块替换算法**全由**硬件实现**，因此Cache— 主存存储器层次对应用程序员和系统程序员都是透明的

造成Cache与主存不一致的原因：**多CPU和IO设备共享主存，不共享Cache**

多处理机共享Cache的难度

- Cache的容量必须大大增加
- 共享Cache的物理位置很难同时靠近多个CPU，延时会增加
- Cache的频宽难以支持两个以上的CPU同时访问

Cache与主存不一致的两种情况

- 由于CPU写Cache，**没有立即写主存**
- 由于IO处理机或IO设备**写主存**

写回法（抵触修改法，WB）：在CPU执行写操作时，信息**只写回Cache**，仅当需要**被替换**时，才将已**被写入**过的Cache块送回主存再调入新块

写直达法（直达法，WT）：利用Cache—主存存储层次在**处理机和主存之间的直接通路**，每当处理机写入Cache同时，也通过此通路直接写入主存。

优缺点比较：

- 可靠性：写直达法由于写回法
- 与主存通信量：写回法少于写直达法
- 控制复杂性：写直达法比写回法简单
- 硬件实现的代价：写回法要比写直达法好
- 采用何种算法与适用场合有关：单处理机（节省成本）用写回法；共享多处理机（保证信息交换可靠）用写直达法

共享主存多CPU系统存在的问题：**仅靠直写法不能保证同一主存单元在各Cache中对应内容一致**

##### 共享主存多CPU系统保持内容一致性解决方法（**）

- 播写法
  - 任何处理机要写入Cache时，写入自己Cache的目标块和主存中
  - **播写**所有Cache中有此单元的地方，或者让所有Cache中有此单元的块作废
- 控制某些**共享信息**不得进入Cache
  - 如信号灯、作业队
- 目录表法
  - 在CPU读、写Cache不命中时，先查主存中的目录表，以判定目标块是否在别的Cache内，以及是否正在被修改等


#### P158 4-14

### 三级存储体系 

## 第五章 标量处理机

加快机器语言解释的两种方式

1. 通过选**用更高速的器件**，采用**更好的运算方法**、提高指令内各微操作的**并行程度**，**减少解释过程所需要的拍数**，以加快每条指令的解释

2. 指令流水线技术：通过控制机构采用同时**解释两条**、**多条**以至整段程序的控制方式，加快整个机器语言程序的解释

   **重叠、流水**

### 重叠方式

#### 重叠原理与一次重叠

解释一条指令的微操作可归并成**取指令**、**分析**和**执行**三部分。

- 取指令：按指令计数器的内容访主存，取出该指令送到**指令寄存器**。
- 指令的分析：对指令的**操作码进行译码**，按寻址方式和地址字段形成**操作数真地址**，并用此真地址去**取操作数**，为执行下一条指令还要形成**下条指令地址**
- 指令的执行：对操作数进行**运算、处理**，或**存储运算结果**

##### 顺序解释（**）

各指令之间顺序串行地进行，每条指令内部的各个微操作也顺序串行执行

- 优点：控制简单，方便进行时序控制
- 缺点：利用率低，速度低

##### 重叠解释

**在解释第$k$条指令的操作完成之前，就可开始解释第$k+1$条指令**。虽然不能加快一条指令的实现，却能加快相邻两条以至整段程序的解释

##### 重叠解释的要求

1. 解决访主存的**冲突**

   - **操作数**和**指令**分别存放于两个**独立编址**且可**同时访问的存储器**中。有利于实现指令的保护，但是增加了主存总线控制的复杂性和软件设计的麻烦
   - 采用多提交叉主存结构，第$k$条的操作数和第$k+1$条指令不在同一个个体内。存在一定局限性
   - 增设采用**先进先出**方式工作的**指令缓冲寄存器**（指缓）趁主存有空时，预取下一条或下几条指令于指缓中

2. 解决”分析“和”执行“操作的并行

   硬件上应有独立的**指令分析部件**和**指令执行部件**。例如，在加法运算中，单独的地址加法器用于地址计算，执行部件也有单独的加法器完成操作数相加

3. 解决”分析“和”执行“操作控制上的同步

   ”分析“和”执行“所需要的时间不同，需要在硬件中解决**控制上的同步问题**，保证任何时候都只是”执行“与”分析“重叠执行

   一次重叠：指令分析部件和执行部件任何时候都只有**相邻两条指令**在重叠解释

   节省硬件，简化控制

4. 解决指令间各种相关问题

   - 数据相关：在执行本条指令过程中，如果用到的**指令、操作数、变址位移量**等正是前面指令执行的**结果**，则必须**等待前面的指令完成**，并把**结果写到主存或通用寄存器之后**，本条指令才开始执行。
     - 指令相关
     - 主存操作数相关 （延迟）
     - 通用寄存器相关
   - 控制相关：由条件分支指令、转子程序指令、中断等引起的相关

#### 相关处理

1. 转移指令的处理
2. 指令相关的处理
3. 主存空间数相关的处理
4. 通用寄存器组相关的处理

### 流水方式

#### 基本概念

##### 工作原理

采用指缓的处理机中，一条指令的解释可以分解为“**分析**”和“**执行**”两个子过程。在指令分析器和指令执行部件的输出端各有一个**锁存器**，可以分别保存指令“分析”和指令“执行”的结果

指令串行—>一次重叠，机器的最大吞吐率提高了一倍

流水将一条指令的解释**分解为更多的子过程**

一次重叠：2个子过程

流水：多个子过程

##### 流水线特点

- 流水线中处理的必须是**连续任务**，只有**连续不断地提供任务**才能充分发挥流水线的效率
- 把一个任务分解为**几个有联系的子任务**，**每个子任务由一个专门的功能部件**来实现
- 流水线中**各段的时间应尽量相等**，否则将引起“堵塞”、“断流”等
- 流水线需要有“**装入时间**”和“**排空时间**”

##### 流水线分析

- 如果把一条指令的解释分解成时间相等的m各子过程，则每隔 $\Delta t = T/m$就可以处理一条指令
- 流水的最大吞吐率取决于子过程的经过时间$\Delta t $，$\Delta t$ 越小，**流水的最大吞吐率就越高**
- 部件之间设有锁存器，**受同一时钟信号控制**，以实现各子部件信息的同步推进
- 时钟信号**不得低于速度最慢部件的经过时间与锁存器的存取时间之和**，还要考虑时钟信号到各锁存器可能存在的延时
- 子过程的细分会**因锁存器数增多而增大任务或指令流水流过流水线的时间**，这在一定程度上会抵消子过程细分使吞吐率提高的好处
- 由于流水线从开始启动到流出第一个结果，需要经过一段流水线建立时间，因此**实际吞吐率总是低于其最大吞吐率**

##### 流水线的分类—多功能的链接方式

**静态流水线**：在同一段时间内，多功能流水线中的各个功能只能**按照一种固定的方式连接**，实现一种固定的功能，只有当按照这种连接方式工作的所有任务**都流出流水线之后**，多功能流水线才能重新连接，以实现其他功能

**动态流水线**：在同一段时间内，多功能流水线中的各段可以按照不同的方式连接，在各个功能部件之间不发生冲突的前提下，**同时执行多种功能**

##### 流水线的分类—是否有反馈信号

按照流水线的各个功能段之间是否有反馈信号，可以把流水线分为**线性流水线**和**非线性流水线**

- 线性：每个流水段都流过一次，且仅流过一次，通常**只完成一种固定的功能**
- 非线性：在流水线的某些流水段之间有**反馈回路或前馈回路** 

#### 标量流水线的主要性能

##### 吞吐率

吞吐率：**单位时间**内**流水线所完成的任务数量**或输出的结果数量

若各个子过程经过的时间都是$\Delta t_2$，则最大吞吐率为： $T_{p_{max}} = 1/\Delta t_2$ 

若各个子过程进行的工作不同，所经过的时间也不一定相同，所以在子过程之间设置接口锁存器，让各个锁存器都受同一时钟的同步 $T_{p_{max}} = \frac {1}{max\{\Delta t_1,\Delta t_2 , \Delta t_3 ,\Delta t_4\}}$ 

受限于流水线中最慢子过程经过的时间。流水线中经过最长时间的子过程称为瓶颈子过程

消除瓶颈的方法

- 细分
- 瓶颈段并联

##### 加速比

指**流水线的速度**与**等效的非流水线**的速度之比

$T_{非流水} = n * m * \Delta t_0$

$S_p = \frac {T_{非流水}}{T} = \frac{nm\Delta t_0}{m\Delta t_0 + (n-1)\Delta t_0} = \frac {m}{1+\frac{m-1}{n}}$ 

##### 效率

指流水线中的**设备实际使用时间**占**整个运行时间之比**，也称流水线设备的时间利用率

如果是线性流水线，且各段经过时间相等，则在T时间内，流水线的效率都相等，均为 $\eta _0$

即 $\eta _1 = \eta _2 = … = \frac {n\Delta t_0}{T}=\frac{n}{m+(n-1)}$ 

整个流水线的效率$ \eta = \frac {\eta _0 + \eta _1 + … + \eta _m}{m} =  \frac{m\eta _0}{m}=\frac{mn\Delta t_0}{mT}$ 

式中分母$mT$ 是时空图中m个段和流水总时间T所围成的面积，分子$mn\Delta t_0$是时空图中n个任务实际使用的面积。从时空图看，效率实际上就是n个任务占用的时空区面积和m个段总的时空区面积之比

##### P117

#### 标量流水机的相关处理和控制机构

流水线只有**连续不断地流动**，不出现断流，才能获得高效率。如果处理不恰当，就会使流水效率显著下降

造成断流的原因：

- 编译形成的目标程序不能发挥流水结构作用
- 存储系统提供不上连续流动所需的指令/操作数
- 相关
- 中断
- 非线性流水线引起的冲突

##### 局部相关的处理

指令相关、主存操作数相关、通用寄存器组相关、基址值或变址值相关

在机器同时解释多条指令之间出现了对同一主存单元或寄存器要求“先读后写“而产生的。

- 推后后续指令对相关单元的读，直至在先的指令写入完成
- 设置相关通路，将运算结果经过相关直接通路直接送入所需部件

##### 全局相关的处理（**）

转移指令和其后的指令之间存在关联

- 猜测法

  条件转移指令占20%，其中转移成功的概率有约占其中的60%。如果概率相近，则宜选择转移不成功分支；如果转移的两个分支概率不均等，宜猜高概率分支

- 加快和提前形成条件码

  加快单条指令内部条件码的形成，不等指令执行完就提前形成反映运算结果的条件码。例如乘除结果可以在实际运算前完成

- 采取延迟转移

  采用软件方法进行静态指令调度。在编译时，将转移指令与其前面不相关的**一条或多条指令交换位置**，让成功转移总是延迟到这一条或多条指令执行之后再进行

- 加快短循环程序的处理

  将长度小于指缓容量的**短循环程序**整个一次性放入指缓内，并暂停预取指令，避免循环执行过程中由于指令预取操作将需要循环执行的指令冲掉，减少主存重复读取次数。

##### 流水机器的中断处理

中断会引起流水线断流，但是其出现概率比条件转移的概率要低得多，且又是随机发生的。所以，对流水机器的中断，主要应考虑如何**处理好断点现场的保护和恢复**，而不是如何缩短流水线的断流时间。

##### 非线性流水线调度

- 由于非线性流水线有反馈回路，在流入新任务时，可能会出现几个任务争用同一功能段的冲突现象。

- 流水线任务调度：相邻任务间隔多少拍进入流水线的调度问题
  - 不冲突
  - 平均延迟最短
  - 尽可能提高的吞吐率与效率

- 对非线性流水线，采用**二维预约表**来实现任务优化调度与优化

- K段单功能非线性流水线，**每个任务通过流水线需要N拍**

- 拍号：任务经过流水线的时钟节拍号

- 向一条非线性流水线的输入端连续输入两个任务之间间隔称为**非线性流水线的启动距离**或**等待时间**。

- 延迟禁止表：将流水线中**所有各段**对一个任务流过时会争用同一段的***节拍间隔数***汇集在一起。

- 冲突向量：用$N-1$ 位的位向量来表示后续新任务间隔各种不同拍数送入流水线时，是否会发生功能段使用的冲突

  $（C_{n-1},…,C_i,…,C_2,C_1)$ 中第 $i$ 位的状态用以表示与当时相隔 $i$ 拍给流水线送入后继任务是否会发生功能段的使用冲突。发生1，不发生0

- 由初始冲突向量$C_0$ 形成状态转换图

  $C_0 $每过一拍逻辑右移一位，若移除0，则允许后续指令进入流水线，再与$C_0$按位“或”，形成新的冲突向量$C_i$

#### P185计算 冲突向量

### 指令级高度并行的超出处理机

- 超标量处理机：**多条指令流水线**，每个$\Delta t$同时流出m条指令（称为度m），靠编译程序优化指令执行顺序。

  组成：冗余设置，多套部件，多部件并发工作

- 超流水线处理机：每个$\Delta t$只流出一条指令，但$\Delta t$很小，同**超标量相比**(度为m)，是其节拍(单位时间)的$1/m$。

  超流水线是**单流水线**，$\Delta t'$非常小，相当于原流水线的$\Delta t'$=$\Delta t/m$ 。

- 超长指令字处理机：编译时找出潜在并行性，进行单指令，多操作码，多数据压缩，形成超长指令。执行时不检测并行性与相关性，直接执行。

#### 超标量处理机基本结构

- 一般流水线处理机：

  - 一条指令流水线
  - 一个多功能操作部件，每个时钟周期平均执行指令的条数小于1。

- 多操作部件处理机：

  - 一条指令流水线
  - 多个独立的操作部件，操作部件可以采用流水线，也可以不流水
  - 多操作部件处理机的指令级并行度小于1

- 超标量处理机典型结构：

  * 多条指令流水线
  * 进的超标量处理机有:定点处理部件CPU，浮点处理部件FPU,图形加速部件GPU


* 大量的通用寄存器，两个一级高速Cache
* 超标量处理机的指令级并行度大于1

#### 超流水线处理机

两种定义：

- 一个周期内能够**分时**发射多条指令的处理机称为超流水线处理机
- 指令流水线有**8个或更多功能段**的流水线处理机称为超流水线处理机

提高处理机性能的不同方法：

- 超标量处理机是通过**增加硬件资源**为代价来换取处理机性能的。
- 超流水线处理机则通过**各硬件部件充分重叠工作**来提高处理机性能。

两种不同并行性：

- 超标量处理机采用的是**空间**并行性
- 超流水线处理机采用的是**时间**并行性

#### 超标量超流水线处理机

- 把超标量与超流水线技术结合在一起，就称为**超标量超流水线处理机**

- 指令执行时序

  超标量超流水线处理机在一个Δ𝑡′ = Δ𝑡/𝑛时钟周期内分时发射𝑘条指令，相当于每个时钟周期Δ𝑡总共发射指令𝑛𝑘条。


  ​				
  ​			
  ​		
  	